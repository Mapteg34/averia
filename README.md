# README #

Предложение по тестовому заданию для компании Averia

### Постановка задачи ###

https://gist.github.com/AlexGx/604cd0fedb86d70a5032280f726189a3

описание

устройство отправляет сообщения (назовем их пакеты) с навигационными данными и данными об активности

- пакеты могут дублироваться
- пакеты могут прийти не в хронологическом порядке

авторизационные данные находятся в заголовке HTTP, payload в теле сообщения, все как обычно

существует 2 вида пакетов:

пакет "Трек" содержит поля:
- int8 статус устройства
- int32 таймстамп в UTC
- floаt "lat" широта в градусах
- float "lon" долгота в градусах
- int8 высота в метрах
- int8 "accu" точность в метрах

пакет "Активность" содержит поля:
- int8 статус устройства
- int32 таймстамп в UTC
- int8 тип активности (0 - сон,1 - шаг,3 - галоп,6 - рысь,255 - шаги не измеряются)
- int кол-во шагов

эти пакеты отправляются независимо. пакеты "трек" отправляются только когда устройство в режиме прогулки. пакеты активность отправляются почти всегда

необходимо описать алгоритм работы (втч можно использовать псевдокод, блок-схемы), применяемые технологии, архитектурные и инфраструктурные решения, решения для задачи обработки поступающих пакетов

сервис должен уметь:

- отсеивать дублирующиеся пакеты (по типу пакета и timestamp)
- отдавать последнюю координату устройства
- отдавать текущие координаты устройств внутри определенного bounding box
- сохранять и агрегировать статистику по активности, отдельно вычислять активность которая была в рамках записи трека
- отправлять пуш уведомления при изменения статус устройства
- описать алгоритм работы подсистемы, вычисляющей совместные прогулки

совместные прогулки

прогулка является совместной если 2 устройства находились рядом (на расстоянии до 6 метров) в течение N минут (N=10), вычисления производятся на
основе данных трека (координаты и timestamp)
стоит обратить внимание:

- совместная прогулка может содержать более 2х устройств, необходимо вычислять пары прогулок для каждого из устройств
- совместная прогулка может прерываться и возобновляться в рамках одного трека (гуляли-разошлись-потом опять встретились)
- совместная прогулка одного устройства, может пересекаться с N совместных прогулок другого устройства
- нет гарантии что треки попадают на сервер сразу (например, устройство одного участника загружает трек сразу, а устройство другого участника через 8 часов), продумать
механизм дообсчета "старых" треков

### Предлагаемое решение ###

#### Предыстория ####

На самом деле подобную задачу ранее я уже реализовывал в рамках проекта tinyIMCS для компании http://www.ibs-a.ru/.
Там конечно были не умные ошейники, а стационарные (в рамках транспортного средства) трекеры
(https://teltonika.ru/, omnicomm, novacom и другие) с подключенными датчиками, работавшие на низкоуровневом протоколе.

Устройства "копили" пакеты, а при появлении "окна" связи отсылали их пачками на сервер.
Без хронологии, часто с большими latency. Пакеты надо было принять, отчитаться устройствам о успехе,
сложить в базу для последующей обработки. Ну а потом из этой базы они синхронизацией "перекачивались" в фронт-приложение,
которое уже позволяло с ними работать: смотреть за статусом, перемещениями, треками, строить отчеты и т.п.
В данном проекте использовалось 1С:ЦСМ.

#### Вернемся к задаче ####

Конечно описание задачи достаточно сумбурное и требует множества уточнений и детальной проработки.

И тем не менее постараюсь изложить мое виденье "решения" проблемы и как бы я его делал.

#### Сервис сбора ####

Во-первых, надо разобраться с протоколом работы конечного устройства.
Если это HTTP как написано в задаче - то это один разговор.
Но на практике для таких устройств HTTP избыточен и часто используют более низкоуровневые решения
(меньше трафика суммарно, меньше пакетов в обе стороны количественно. итог: быстрее и дешевле).

В случае низкоуровневых протоколов для приема был бы сервер на C++ который по заданному формату принимал
все сообщения от клиентов и складывал их в буфер (очередь, или возможно промежуточная база, все зависит от
цифр и конкретной реализации). Не забываем про балансировку и горизонтальное масштабирование как самого сервиса,
так и очереди (опять же не ясно нужны ли они, но смотрим по максимуму). 

В случае HTTP думаю проще реализовать какой-то сборщик на готовых решениях.
Например, та же лара умеет из коробки все необходимое и может быть горизонтально масштабируемым микросервисом.
Но конечно PHP тут жирновато (опять же нужны цифры, но берем максимум).
И да, стек очередей на PHP может работать не так как мы того ожидаем)

Можно реализовать на ноде, но задачи хранить промежуточное состояние тут не просматривается, а в остальном
едва ли оно будет быстрее PHP.

Можно посмотреть Go, там стек очередей все-таки работает получше.

А можно посмотреть на более серьезные решения, их сейчас на рынке много
(исходя из инфраструктуры и цифр надо выбирать уже более корректно), пример: https://github.com/oktal/pistache

Это сервис предварительного сбора данных. Его задача - быстро получить от клиента, кинуть в очередь.
Масштабироваться, реагировать на возрастание нагрузки (докидывая ноды в пул).
Опять же можно посмотреть и на готовые решения https://aws.amazon.com/ru/getting-started/serverless-web-app/module-4/.

#### Очередь ####

Тут просто кластер, собственно особой разницы что использовать нет, зависит от инфраструктуры.
RabbitMQ как наиболее простое и распространенное.

#### База ####

Ну так как в вакансии mysql, то пусть mysql. Кластер. Часть на запись. Часть на чтение.
Кластеризация пакетов в разрезе дат (месяцы/недели), глобально тут надо смотреть что мы потом фронту отдаем и решать исходя из этого.

#### Синхронизация (однонаправленная) пакетов из очереди в базу ####

Ну тут все достаточно просто. Воркеры в неограниченном количестве. Снимаем событие с очереди.
Чекаем наличие в базе, при отсутствии - дописываем.
Как раз тут мы и решаем задачу "отсеивать дублирующиеся пакеты (по типу пакета и timestamp)".

#### Optional. Аппроксимация ####

После того как наши пакеты в базе, можно иногда их сглаживать (точность то у нас совсем не огонь).
Таски фоновые. Периодически поджимают и выравнивают значения. Может быть "там же". Может быть "из сорцов в чистое".
Может быть при создании очередной точки кластеризации. А может быть и вообще не надо)

#### Front api ####

Тут мы решаем 2 поставленных задачи:
* отдавать последнюю координату устройства
* отдавать текущие координаты устройств внутри определенного bounding box

Собственно данные в базе есть, а уж прокси к ним написать не проблема. Lara/yii/etc(тысячи их) значения имхо не имеет.
Если тут клиент подождет лишние 100-200мс, видимо не критично (опять же я вижу только кусочек айсберга в задании, могу ошибиться).

#### Неясные пункты ####

* сохранять и агрегировать статистику по активности, отдельно вычислять активность, которая была в рамках записи трека
* отправлять пуш уведомления при изменения статус устройства

Тут основной вопрос: хотим мы это в реалтайме (а я так понял что нет) - тогда один разговор. Может все вышеописанное и "не в ту степь".
Может нам все-таки надо иметь текущий статус между "пакетами" и откидывать его клиенту? Врятли, что ошейник с ними делать будет?)

Наверное, все-таки имелось ввиду что пользователь потом, придя домой, вечером за чашечкой чая хочет это посмотреть.
Ну тогда собственно api'шка выше все это решит. Ну и фронт на Vue+SPA(обернутый в PWA, ниже описано зачем).

А может имелось ввиду мобильное приложение, которое прям в реалтайме это выводит пока мы гуляем с нашим питомцем.
Ну тогда с слоя "синхронизации" можно генерить доп событие. Его отдельным слоем воркеров хватать и обсчитывать.
Текущее состояние хранить в мемкеше (доступном всем). Сами пуши - кидать в отдельную очередь и вечать подписчикам через
тот же websocket (однонаправленный Broadcasting есть в ларе из коробки, и весьма годен).

Само мобильно приложение закидываем в PWA и получаем и фоновые синки (подписки, если websocket) и доступ к пушам, и возможность
"установить приложение", хотя по сути это все тот-же сайт (или уже нет, когда уже на слово "Сайт" сделают RFC :)

#### Совместные прогулки ####

Во-первых, надо понять что мы считаем "прогулкой"?
Если это ограниченный с двух сторон по времени "промежуток", то:

* Берем начало и конец промежутка.
* Пользователя знаем, берем его пакеты. (координаты, время).
* Определяем окружность зоны "прогулки".
* Берем все пакеты других пользователей в нашем временном промежутке и в нашей "зоне", группируем по пользователям.
* Перебираем, ищем попадания (на расстоянии до 6 метров, N минут и т.п.).
(тут опять же надо уточнить требования: если А и Б находились рядом, но при этом был еще С не рядом с А, но рядом с Б
, то считать это совместной АБС или только АБ?)
* итоги в кеш
* ...
* PROFIT

Ну и опять же: когда мы хотим это показать пользователю? реалтайм? потом? завтра?
Пересчет когда делать? Периодически(по расписанию)? По запросу? По событию?
Рамки ("например, устройство одного участника загружает трек сразу, а устройство другого участника через 8 часов")?
А если 24 часа? А если месяц?

В общем вопросов много, но принципиальный алгоритм выше. Опять же надо смотреть готовые решения, ибо для ГИС
каких только алгоритмов уже не выпустили и придумывать свой математический велосипед совсем не стоит.

#### Если осилили ####

Хей хей хей. Я в Волгограде. И от вас даже кто-то мне звонил. Но потом пропал (.
А так пообщаться буду рад. Могу я к вам (офис у вас вроде красивый). Можете вы ко мне
(конечно до уровня я со своим подвальчиком недотягиваю, но чай/кофе будет).
В общем надо общаться ;)

P.S. А да, там вы еще докер упоминали. Надо. Деплой, быстрое развертывание dev хостов.
Но на проде я бы 15 раз подумал. 20 раз наверное даже. Хотя docker swarm и выглядит неплохо
(и даже работает сносно, и даже swarm площадки для размещения стали появляться)
но на прод как-то я боюсь. Но если вы готовы попробовать - то это будет крайне интересный опыт)